# StepA_Bの指示内容（環境整備 & ベースライン評価）

これから StepA〜B（環境整備 & ベースライン評価）を進めたいです。  
基本方針・設計は以下に書かれている内容に従います。

- `docs/今後の方針.md`
- `LLM_ファインチューニング/Step2の指示内容.md`
- `LLM_ファインチューニング/Step2の結果（設計メモ）`
- `LLM_ファインチューニング/Step3_タスク1_結果.md`
- `LLM_ファインチューニング/Step3_タスク2_結果.md`
- `LLM_ファインチューニング/Step3_まとめ.md`
- 実装済みの `scripts/build_finetune_dataset.py` と `scripts/evaluate_multiple_choice.py`

---

## 共通ルール（必ず守ってほしいこと）

- **新しいブランチ**上で作業してください（例：`feature/llm-env-baseline`）。  
  `main` を直接変更しないでください。
- 変更は **小さく分割** してください。
  - A-1 の結果まとめ  
  - A-2 の設定ファイル追加  
  - B-1 のコマンド整理  
  など、タスクごとに別コミットにしてください。
- 破壊的な操作は行わないでください。
  - 例：大量のファイル削除、プロジェクト構成の大きな変更、`pip uninstall` など
- **パッケージインストールやシステム設定変更のコマンドは、提案まで** にしてください。  
  実際にコマンドを実行するかどうかは人間が決めます。
- すべてのタスクについて、最後に  
  **「どのファイルがどう変わったか／どんなコマンドを提案したか」** を Markdown でまとめてください。

---

## A. LLM / RAG 環境整備タスク

### タスクA-1：環境要件の棚卸し

目的：  
statutes-rags を Qwen3:8B + RAG で動かすのに必要な **Python依存 & 外部ソフト** を一覧化します。

やってほしいこと：

1. リポジトリ内の以下を確認してください。
   - `pyproject.toml` または `requirements.txt` 等
   - `rag_config.py`（LLM設定や retriever設定）
   - `RAGPipeline` や `Ollama` / `langchain` に関するインポート部分

2. そこから、
   - 必要な Python パッケージ
     - 例：`langchain`, `langchain-community`, `faiss-cpu` or `faiss-gpu`, `rank_bm25`, `sentence-transformers` など
   - 必要な外部ソフト
     - 例：`Ollama`（Qwen3:8B モデル）、`CUDA` など
   - 必要そうな環境変数
     - 例：`OLLAMA_HOST`, `OMP_NUM_THREADS` など
   を推定し、**Markdown で一覧表**にしてください。

3. 1〜2 の結果を  
   `LLM_ファインチューニング/A_環境要件まとめ.md`  
   というファイルにまとめてください（インストールコマンド例も書いてくださいが、実行はしないでください）。

---

### タスクA-2：Python 依存パッケージのインストール方針整理

目的：  
実際に使う Python 環境に対して、**どの `pip install` コマンドを打てばよいか** を整理します。

やってほしいこと：

1. タスクA-1の結果をもとに、  
   現在のプロジェクトに必要な pip パッケージをリストアップしてください。
2. それを
   - `requirements-llm.txt`（または既存の requirements に追記）としてまとめる案
   - あるいは `pip install ...` 一発コマンド案
   のどちらかで提案してください。
3. 提案内容を  
   `LLM_ファインチューニング/A_環境セットアップコマンド.md`  
   として Markdown にまとめてください。
4. **実際に `pip install` は実行しないでください。**  
   コマンドを提示するところまでで構いません。

---

### タスクA-3：OMP / 共有メモリエラー回避のメモ作成

目的：  
Step3 で発生した OMP / SHM 関連エラーに対して、**環境側でどう対処すべきかの候補**を整理します。

やってほしいこと：

1. `Step3_タスク2_結果.md` や `Step3_まとめ.md` に書いてあるエラー内容を確認してください。
2. それを簡単に要約し、
   - `OMP_NUM_THREADS=1` などの環境変数設定
   - `ulimit -n` / 共有メモリなど、一般的に考えられる対処策
   をいくつか提案してください（あくまで「候補の列挙」です）。
3. これを  
   `LLM_ファインチューニング/A_OMPエラー対策メモ.md`  
   として Markdown で保存してください。
4. 実際に環境変数を設定したり、システム設定を変えたりは **行わないでください**。  
   提案だけにしてください。

---

## B. ベースライン評価タスク

### タスクB-1：少数問での evaluate_multiple_choice.py 実行プラン作成

目的：  
LLM が接続できたあとにすぐ試せるように、**少数問（3〜5問）の実行コマンド案**を作っておきます。

やってほしいこと：

1. `scripts/evaluate_multiple_choice.py` の `main()` と CLI オプションを確認してください。
2. `--no-rag` / `--samples` / `--use-cot` などのオプションの有無と意味を整理してください。
3. Qwen3:8B（ベースモデル）を使い、**3〜5問だけ評価する**ためのコマンド例を 2パターン提案してください。
   - 例：
     - パターン1：`--no-rag`（純 LLM ベースライン）
     - パターン2：RAG あり（top_k 小さめ）でのベースライン
4. 上記を  
   `LLM_ファインチューニング/B_ベースライン実行コマンド_少数問.md`  
   として Markdown にまとめてください。
5. このタスクでは **実際にコマンドを実行しないでください。**  
   あくまで「後で人間がコピペして実行するためのコマンド案」を作るだけにしてください。

---

### タスクB-2：本番 140問ベースラインの実行プラン作成

目的：  
研究の共通条件（問題数 140問／全件インデックス／LLM: Qwen3:8B）に沿った **本番評価コマンド**を用意します。

やってほしいこと：

1. lawqa_jp の 140問（今回使う selection）を対象に、
   - RAG あり（全件インデックスを使う）
   - retriever の top_k や reranker の有無は、現状の推奨値（Step3で使っている設定）をベースにする
2. 上記条件で evaluate_multiple_choice.py を動かすためのコマンド案を 1〜2 パターン提案してください。
   - 例：
     - CoT なし（direct）ベースライン
     - CoT ありベースライン（必要なら）
3. それらのコマンドを  
   `LLM_ファインチューニング/B_ベースライン実行コマンド_本番140問.md`  
   に Markdown でまとめてください。
4. 余裕があれば、**実行にかかりそうな時間の目安** や  
   「GPU が無い場合はかなり遅くなる」などの注意点もコメントとして書いてください。
5. このタスクでも **コマンドは実行しないでください。**  
   実行は、環境が整った後で人間が行います。

---

### タスクB-3：ベースライン評価のログテンプレ作成

目的：  
あとで Base vs Fine-tuned の比較がしやすいように、**ベースライン結果を書き込むテンプレート**を先に用意しておきます。

やってほしいこと：

1. Baseモデル（Qwen3:8B）用のベースライン結果を記録するための Markdown テンプレートを作成してください。
   - 含めたい項目の例：
     - 実行日時
     - 使用モデル名
     - retriever設定（type, top_k, reranker有無）
     - RAG 有無
     - CoT 有無
     - 正答率（全体 / 必要ならカテゴリ別）
     - 実行コマンド
     - 実行環境メモ（GPU種別、メモリなど）
2. このテンプレートを  
   `LLM_ファインチューニング/B_ベースライン結果テンプレート.md`  
   として保存してください。
3. まだ結果は書き込まず、**空テンプレの状態**で残してください。

---

以上のタスクを、この順番で実行してください。  
各タスクの完了時には、**何を調べ／どんなコマンドやファイル案を作ったか**を Markdown に残してください。
