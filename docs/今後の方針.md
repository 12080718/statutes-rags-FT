# statutes-rags リポジトリ改造の今後の方針

## 0. プロジェクト概要

- このリポジトリは **法令 RAG（statutes-rags）** である。
- 本プロジェクトの目的：
  1. **Fine-tuning 用データ生成機能の追加**
  2. **Fine-tuned LLM を既存評価パイプラインに組み込めるようにする**
- 既存機能（特に CLI を用いた評価パイプライン）の挙動は壊さない。

---

## 1. Codex Agent 利用時の行動原則

Codex（Agent Mode）を使うときは、以下を必ず守る。

- 作業は必ず `git` のブランチ上で行う  
  - 例：`git checkout -b feature/llm-ft`  
  - `main` を直接書き換えない。
- 破壊的な操作は行わない  
  - 例：大量のファイル削除、`pip uninstall`、OS レベルの設定変更など  
  - これらは **「提案」まで** とし、実行するかは人間が判断する。
- 既存の評価スクリプトや実験条件を変える場合は、  
  変更箇所と影響範囲を必ずコメント or Markdown に残す。
- タスクは **小さく分割して依頼 → 自分でレビュー → commit** のサイクルで進める。

---

## 2. 開発フェーズの全体像

### フェーズ1：リポジトリ構造の理解（読んで整理させる）

目的：**既存コードの役割を Codex と共有する**。

- 行うこと
  - `app/`, `scripts/`, `datasets/` を中心に、  
    各ディレクトリ／主要ファイルの役割を要約させる。
  - 特に以下を重点的に説明させる：
    - `app/core/rag_config.py`  
      - 設定の読み込み・RAGConfig の構造
    - `app/retrieval/rag_pipeline.py`  
      - RAG の処理フロー（retrieval → rerank → LLM 呼び出し）
    - `scripts/evaluate_multiple_choice.py`  
      - 4択プロンプトの生成位置と LLM 呼び出し部分
- ゴール
  - 「どのレイヤーをどのファイルが担当しているか」を文章として整理する。

---

### フェーズ2：設計方針を文章として固める

目的：**既存コードを壊さずに何を“増築”するか決める**。

- Codex への依頼例
  - 「既存コードを壊さずに、以下を追加したい：
    1. Fine-tune 用データ生成スクリプト  
    2. プロンプト共通化モジュール  
    3. `rag_config` の拡張  
    4. `evaluate_multiple_choice` のモデル切り替え機能  
    それぞれどのファイルに何を足すか、箇条書きで設計案を出してほしい。」
- その設計案を `docs/llm_ft_plan.md` などに保存する。

---

### フェーズ3：安全なところ（新規ファイル）から実装する

目的：**既存コードに触る前に、追加モジュールだけ作る**。

- 新規に作成する想定のファイル
  - `app/core/prompts.py`
    - 法令 4択問題のプロンプトテンプレート（CoT 用／直接回答用）を関数として定義。
  - `scripts/build_finetune_dataset.py`
    - lawqa_jp などの 4択データ
      → retrieval
      → `input` / `output` 形式の JSONL へ変換。
- 依頼のポイント
  - まずは docstring と型ヒントを厚めに書かせる。
  - 実装は最小限でよいので、あとから人間が読んで直しやすい形を優先する。
- 実装後は必ず人間がコードレビューし、問題なければ commit する。

---

### フェーズ4：既存コードとの“ひも付け”を少しずつ行う

目的：**共通モジュールを既存スクリプトに組み込む**。

- 主に変更するファイル
  - `scripts/evaluate_multiple_choice.py`
    - 4択プロンプトの直書き部分を、
      - `from app.core.prompts import build_mc_prompt`  
        のような呼び出しに差し替える。
    - `--llm-model` や `--llm-profile` 等の CLI オプションを追加し、  
      `rag_config` 経由で LLM モデル名を切り替えられるようにする。
- 指示の仕方
  - 「このファイルのこの関数だけを書き換えて」と scope を小さく指定する。

---

### フェーズ5：Fine-tune 用データ生成の実装

目的：**RA-DIT 風の「retrieval 付き学習データ」を作れるようにする**。

- 想定フロー
  1. lawqa_jp の JSON を読み込む。
  2. RAGPipeline（または retriever 部分のラッパ）を使って、  
     各問題から top-k 条文チャンクを取得する。
  3. `prompts.py` のテンプレを用いて
     - `input`（Background + 質問 + 選択肢）  
     - `output`（理由 + 最終 Answer / あるいは Answer のみ）
     を生成する。
  4. それらを JSONL（例：`{"input": ..., "output": ..., "meta": ...}`）で保存する。
- 実装時のステップ
  - まずは「1問だけ処理するデモ」を作り、
  - 次に「全件を処理するループ」に拡張する。

---

### フェーズ6：Fine-tuned モデルの評価ループ整備

目的：**ベースモデルと Fine-tuned モデルを同一条件で比較できるようにする**。

- 前提
  - Fine-tuned Qwen を Ollama 側に登録しておく（例：`qwen3-law-ft`）。
- `rag_config` の拡張
  - `LLM_BASE_MODEL`, `LLM_FINETUNED_MODEL` などの項目を追加。
- `evaluate_multiple_choice.py` の拡張
  - CLI からベース / FT モデルを選択できるようにする。
  - 140 問共通セットで、複数設定（base / FT / no-RAG など）をまとめて評価できるようにする。
- 追加でやりたいこと
  - base vs finetuned の結果をまとめたログ（正答率、場合によっては混同行列）を出力。
  - 変更内容の要約を `README_ft.md` 等に残す。

---

## 3. 運用ルール（常に意識しておくこと）

- **小さなタスクに分割 → Codex に実装 or 修正案を出させる → 自分でレビュー → commit**  
  というサイクルを守る。
- タスクが終わるたびに、Codex に
  - 「今回変更されたファイル一覧」
  - 「各ファイルの変更概要」
  を Markdown でまとめてもらい、`docs/` 配下に保存する。
- `git diff` は人間が必ず目を通す。特に以下は要注意：
  - `rag_config.py`, `setup/`, `Makefile`, `pyproject.toml` など環境に影響するファイル。
- 大きなリファクタリング（クラス分割、ファイル削除など）は、  
  Fine-tuning 周りが一通り動作した後のタイミングまで後回しにする。

---
